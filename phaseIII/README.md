# Phase III: Prototypes and User Testing

## Introduction

Odd-Jobs is an application dedicated to providing college students a readily available way to make money doing jobs that other people post. Work done in the first sprint gave us market research to guide our designs. As for this sprint, we created a prototype and testing protocol that allowed us to conduct user tests, to gain feedback on our prototype.

## Methods

Our testing protocol had users complete three tasks. We incorporated a think-aloud protocol to ensure we didn’t miss any of the users feedback, since we were not worried about a user's efficiency. We were only concerned with gathering feedback and ensuring a task could be complete. Task One was to login and look for a job to complete in a given time span. This task tests our employee portal to ensure that a user would be able to accept jobs. Task Two was to login and post a job you would like to be done. We wanted to ensure the user would be able to post jobs they wanted to complete. Our last task was to use the login portal to reset the user password. This was tested to make sure our app is learnable and has some standards that would make the app feel familiar.

We had three stages of questions throughout our user tests. We had background questions before beginning with any test that would gather information such as familiarity with similar apps and to see if there was anything they were missing. After each task we would ask how difficult they found that task and if they had any thoughts about the process. At the end of our user tests we asked debriefing questions to dive deeper into users' thoughts about each task. We wanted to focus on individual tasks and gather general feedback such as specific parts or processes they liked and disliked.


## Findings

Our findings through the usability test offered very helpful insights into the shortcomings of our current prototype and features that could be improved. For our first scenario of the six users, we had an average difficulty scale of 3.83 out of 5 (1 is hard, 5 is easy). This was due in part to the wording of the login menu on the first page, which confused 2 out of 6 of our participants.

Scenario 2 had an average difficulty of 4.16, which came down to the need for different accessibility features like a “set home location” for job postings and feedback when users hit certain buttons like “post job”. These features were mentioned by 5 out of the 6 participants and would aid the user greatly by making the whole experience more efficient.

The last scenario, number 3, had an average difficulty rating of 4.5 and was easy to finish for 4 out of the 6 participants. One of the participants had a harder time, because one of our moderators did not realize that Figma had a “fit to screen” option. The other participant noted how the “reset password” page account selection dropdown menu was not functioning.


## Conclusions

The UX team discovered that there was a need to rename the titles for the login page. We also discovered a crucial design oversight, we had forgotten to put in a way to get back to the page from anywhere in the prototype. One of the participants also mentioned that instead of having two logins, we just have a way of switching between the different roles. A lack of feedback regarding when buttons were pressed was also brought up, along with confirmation windows when accepting and posting jobs. When users are posting jobs, having a way to set a home location that automatically fills in the “end location” menu was mentioned as being standard for other job for hire applications, which would aid in the job posting process. The same goes for having a “right now” option when users are posting jobs. In regards to the “reset password” page, the drop down menu for selecting which account the user needed to reset did not function properly.

## Caveats

Throughout our user testing we discovered a few limitations to our study. One of our caveats is that this is just a prototype so there is missing functionality such as text input, and even the functionality that exists, may be buggy or incomplete from the final product. Another caveat is that while our study included our target audience, college students, they are more technical being primarily CSCI/CINS students so that may have influenced our results.
